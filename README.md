# Proyecto de Gesti√≥n de Datos con SQLite y Web Scraping

## Descripci√≥n

Este proyecto incluye varios scripts en Python dise√±ados para realizar tareas de scraping de datos, almacenamiento en una base de datos SQLite y consulta de informaci√≥n mediante una interfaz gr√°fica.

## Componentes del Proyecto

### 1. Web Scraping con SQLite

- **Archivo:** `006-criterio multiple.py`
- **Descripci√≥n:**
  - Realiza b√∫squedas en `Paginas Amarillas` para obtener informaci√≥n relevante sobre empresas y servicios.
  - Almacena los resultados en una base de datos SQLite (`mercado.db`).
  - Utiliza la librer√≠a `requests` para hacer solicitudes HTTP y `BeautifulSoup` para analizar el contenido HTML.
  - Implementa pausas aleatorias entre solicitudes para evitar bloqueos por parte del servidor.
  
### 2. Buscador de Datos en la Base de Datos

- **Archivo:** `buscador.py`
- **Descripci√≥n:**
  - Proporciona una interfaz gr√°fica desarrollada en `Tkinter` para buscar informaci√≥n en la base de datos `mercado.db`.
  - Permite la consulta de registros en la tabla `target_attributes`.
  - Muestra los resultados en una tabla interactiva con desplazamiento vertical.
  
### 3. Eliminaci√≥n de Duplicados en la Base de Datos

- **Archivo:** `c001-eliminar duplicados.py`
- **Descripci√≥n:**
  - Busca y elimina registros duplicados en la tabla `emails` de la base de datos `mercado.db`.
  - Utiliza consultas SQL para identificar y conservar solo una ocurrencia de cada email.
  - Garantiza la limpieza y consistencia de los datos almacenados.

## Instalaci√≥n y Requisitos

### Requisitos

Este proyecto requiere las siguientes dependencias:
- Python 3.x
- `requests` (para scraping web)
- `beautifulsoup4` (para parseo de HTML)
- `sqlite3` (para manejo de bases de datos)
- `tkinter` (para la interfaz gr√°fica)

Para instalar las dependencias necesarias, ejecutar:

```
pip install requests beautifulsoup4
```

### Configuraci√≥n

1. Clonar el repositorio o descargar los archivos.
2. Asegurarse de que la base de datos `mercado.db` est√° en la misma carpeta que los scripts.
3. Ejecutar `006-criterio multiple.py` para poblar la base de datos.
4. Usar `buscador.py` para consultar los datos almacenados.
5. Ejecutar `c001-eliminar duplicados.py` si es necesario limpiar registros duplicados.

## Uso

### Ejecuci√≥n del Scraper

Para obtener datos de `Paginas Amarillas` y almacenarlos en SQLite:
```
python 006-criterio multiple.py
```

### Uso del Buscador

Para buscar registros en la base de datos desde la interfaz gr√°fica:
```
python buscador.py
```

### Eliminaci√≥n de Duplicados

Para limpiar registros repetidos en la base de datos:
```
python c001-eliminar duplicados.py
```

## Estructura del Proyecto

```
‚îú‚îÄ‚îÄ 006-criterio multiple.py    # Script de web scraping y almacenamiento en SQLite
‚îú‚îÄ‚îÄ buscador.py                 # Interfaz gr√°fica para b√∫squeda en la base de datos
‚îú‚îÄ‚îÄ c001-eliminar duplicados.py  # Eliminaci√≥n de duplicados en SQLite
‚îú‚îÄ‚îÄ mercado.db                   # Base de datos SQLite
```
---


# üìù Explicaci√≥n del c√≥digo de los archivos subidos

---

## 1Ô∏è‚É£ `006-criterio multiple.py`
üìå **Este script extrae informaci√≥n de P√°ginas Amarillas y la almacena en una base de datos SQLite.**

- **Toma palabras clave** y busca empresas en P√°ginas Amarillas.
- **Extrae enlaces de sitios web** de las empresas listadas.
- **Limpia las URLs eliminando par√°metros** y las guarda en `mercado.db`.
- **Realiza m√∫ltiples solicitudes HTTP** con `requests` y `BeautifulSoup`.
- **Evita bloqueos con pausas aleatorias entre peticiones**.

### üîç **C√≥mo funciona**
1. **Define una lista de palabras clave**, como `"web"`, `"programaci√≥n"`, `"marketing"`, etc.
2. **Para cada palabra clave, realiza una b√∫squeda** en P√°ginas Amarillas.
3. **Obtiene los enlaces de empresas** (clase `web` en HTML).
4. **Limpia las URLs** quitando par√°metros innecesarios.
5. **Guarda las URLs en la base de datos SQLite** (`mercado.db`).
6. **Repite el proceso para 4 p√°ginas de resultados por palabra clave**.
7. **Espera entre 2 y 5 segundos** antes de la siguiente petici√≥n para evitar bloqueos.

‚úÖ **√ötil para:** recolectar sitios web de empresas en un nicho espec√≠fico.

---

## 2Ô∏è‚É£ `buscador.py`
üìå **Este script es una interfaz gr√°fica (`Tkinter`) para buscar datos en `mercado.db`.**

- **Permite buscar t√©rminos** en la base de datos.
- **Muestra resultados en una tabla interactiva**.
- **Maneja errores y muestra alertas** si no encuentra coincidencias.

### üîç **C√≥mo funciona**
1. **El usuario ingresa un t√©rmino de b√∫squeda** en una caja de texto.
2. **El script consulta la base de datos (`mercado.db`)** buscando coincidencias en la tabla `target_attributes`.
3. **Muestra los resultados en una tabla**.
4. **Si no hay coincidencias, muestra un mensaje** de "Sin resultados".
5. **Incluye un scrollbar para manejar listas largas**.

‚úÖ **√ötil para:** consultar r√°pidamente las URLs almacenadas en la base de datos.

---

## 3Ô∏è‚É£ `c001-eliminar duplicados.py`
üìå **Este script elimina correos electr√≥nicos duplicados de la base de datos `mercado.db`.**

- **Busca emails repetidos** en la tabla `emails`.
- **Mantiene solo la primera ocurrencia** de cada email.
- **Elimina las copias duplicadas**.

### üîç **C√≥mo funciona**
1. **Conecta a la base de datos SQLite (`mercado.db`)**.
2. **Busca correos electr√≥nicos duplicados** en la tabla `emails`.
3. **Para cada email duplicado**:
   - Encuentra la primera aparici√≥n (con el menor `rowid`).
   - Borra todas las dem√°s copias del email.
4. **Guarda los cambios** y cierra la base de datos.

‚úÖ **√ötil para:** limpiar bases de datos eliminando informaci√≥n redundante.

---

## 4Ô∏è‚É£ `mercado.db`
üìå **Este archivo es una base de datos SQLite** que almacena:
- **Las URLs recolectadas de P√°ginas Amarillas** (`target_attributes` en `006-criterio multiple.py`).
- **Los correos electr√≥nicos de empresas** (`emails`, usado en `c001-eliminar duplicados.py`).

‚úÖ **√ötil para:** manejar datos de empresas de forma estructurada.

---

## üöÄ **Conexi√≥n entre los scripts**
1Ô∏è‚É£ **`006-criterio multiple.py`** ‚Üí Extrae URLs de empresas y las almacena en `mercado.db`.  
2Ô∏è‚É£ **`buscador.py`** ‚Üí Permite buscar las URLs almacenadas en `mercado.db`.  
3Ô∏è‚É£ **`c001-eliminar duplicados.py`** ‚Üí Elimina correos electr√≥nicos repetidos en `mercado.db`.  

‚úÖ **Sistema completo para extraer, almacenar, consultar y limpiar datos de empresas en P√°ginas Amarillas.** üöÄ


